// utils/openai.js

const OpenAI = require('openai');
const { ensureGuildJSON, readJSON } = require('./fileHelper');

/**
 * ã‚®ãƒ«ãƒ‰ã”ã¨ã®ChatGPTè¨­å®šã‚’èª­ã¿è¾¼ã‚€
 * @param {string} guildId
 * @returns {Promise<Object>} config.chatgpt
 */
async function readGuildChatGPTConfig(guildId) {
  const filePath = await ensureGuildJSON(guildId);
  const config = await readJSON(filePath);
  return config.chatgpt || {};
}

/**
 * OpenAI APIå‘¼ã³å‡ºã—ã®å®‰å…¨ãªãƒ©ãƒƒãƒ‘ãƒ¼
 * @param {Function} apiCall - OpenAI APIå‘¼ã³å‡ºã—é–¢æ•°
 * @param {any} fallbackResponse - ã‚¨ãƒ©ãƒ¼æ™‚ã«è¿”ã™ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¬ã‚¹ãƒãƒ³ã‚¹
 * @returns {Promise<any>}
 */
async function safeOpenAICall(apiCall, fallbackResponse) {
  try {
    return await apiCall();
  } catch (error) {
    logger.error('OpenAI API Error', { message: error.message, code: error.code, error });

    let message = 'OpenAI APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚';
    switch (error.code) {
      case 'invalid_api_key':
        message = 'ç„¡åŠ¹ãªAPIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚';
        break;
      case 'insufficient_quota':
        message = 'APIã®åˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚';
        break;
      case 'rate_limit_exceeded':
        message = 'APIã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆåˆ¶é™ã‚’è¶…ãˆã¾ã—ãŸã€‚';
        break;
    }

    return fallbackResponse || { error: true, message };
  }
}

/**
 * ChatGPT APIã‚’å‘¼ã³å‡ºã™ï¼ˆã‚®ãƒ«ãƒ‰ã”ã¨ã®è¨­å®šã‚’é©ç”¨ï¼‰
 * @param {string} prompt - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
 * @param {string} guildId - Discordã‚®ãƒ«ãƒ‰ID
 * @param {Object} [options] - è¿½åŠ ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆOpenAI APIã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‰
 * @returns {Promise<any>}
 */
async function getChatCompletion(prompt, guildId, options = {}) {
  const chatgpt = await readGuildChatGPTConfig(guildId);

  if (!chatgpt.apiKey) {
    return { error: true, message: 'APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚' };
  }

  const openai = new OpenAI({ apiKey: chatgpt.apiKey });

  const defaultOptions = {
    model: chatgpt.model || 'gpt-3.5-turbo',
    messages: [{ role: 'user', content: prompt }],
    max_tokens: chatgpt.maxTokens ?? 150,
    temperature: chatgpt.temperature ?? 0.7,
    ...options,
  };

  return await safeOpenAICall(
    () => openai.chat.completions.create(defaultOptions),
    {
      error: true,
      message: 'ğŸ¤– ç¾åœ¨ã€ChatGPTæ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ã„ãŸã ã‘ã¾ã›ã‚“ã€‚',
    }
  );
}

module.exports = {
  getChatCompletion,
};
